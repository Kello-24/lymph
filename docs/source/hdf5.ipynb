{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 for reproducability\n",
    "\n",
    "When one is doing many rounds of inference with different data and different models, it gets easy to loose track of which sampled parameters refer to which sampling round. To tackle this, we implemented a couple of utility functions and wrappers that should make it easier to keep everything together and reproducable.\n",
    "\n",
    "In this notebook, we are going to walk through a round of sampling and we try to set everything up in a way that would allow someone else to walk in and repeat the \"experiment\" easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Imports & Settings\n",
    "\n",
    "First the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lymph\n",
    "import numpy as np\n",
    "import scipy as sp \n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some settings, e.g. the name of the HDF5 file we would later like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_hdf5_file = \"./_data/demo.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up the Model\n",
    "\n",
    "First, we will set up the model as we would normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {\n",
    "    ('tumor', 'primary'): ['I', 'II', 'III', 'IV'],\n",
    "    ('lnl'  , 'I'):       ['II'], \n",
    "    ('lnl'  , 'II'):      ['III'],\n",
    "    ('lnl'  , 'III'):     ['IV'],\n",
    "    ('lnl'  , 'IV'):      []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = lymph.Bilateral(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_spsn = {\n",
    "    \"MRI\": [0.63, 0.81],\n",
    "    \"PET\": [0.86, 0.79]\n",
    "}\n",
    "original_model.modalities = diagnostic_spsn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some synthetic data we can work with later.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    Note\n",
    "\n",
    "    This step can be skipped, as that data is already in the `./_data` directory. But it may also serve as a guide on how to generate synthetic datasets.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_t = 10\n",
    "t = np.arange(max_t + 1)\n",
    "\n",
    "early_p = 0.3\n",
    "late_p = 0.7\n",
    "\n",
    "early_time_dist = sp.stats.binom.pmf(t, max_t, early_p)\n",
    "late_time_dist = sp.stats.binom.pmf(t, max_t, late_p)\n",
    "time_dists = {\"early\": early_time_dist, \"late\": late_time_dist}\n",
    "\n",
    "original_model.ipsi.base_probs   = [0.05, 0.2 , 0.12, 0.1 ]\n",
    "original_model.contra.base_probs = [0.01, 0.06, 0.03, 0.01]\n",
    "original_model.trans_probs = [0.1, 0.3, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = original_model.generate_dataset(\n",
    "    200, [0.6, 0.4], time_dists=time_dists\n",
    ")\n",
    "synthetic_data.to_csv(\"./_data/bilateral.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the data into the model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = pd.read_csv(\"./_data/bilateral.csv\", header=[0,1,2])\n",
    "original_model.patient_data = synthetic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Store the model in an HDF5 file\n",
    "\n",
    "And before we proceed any further, we store the specifics of this model instance in an HDF5 file. It will basically store the graph, the modalities with their sensitivities & specificities as well as the just loaded data in the HDF5 file and allow us to recreate an instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.to_hdf5(\n",
    "    filename=demo_hdf5_file, \n",
    "    groupname=\"original\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare the sampling\n",
    "\n",
    "In the utilities of the `lymph` package we also provide a small wrapper around the awesome [emcee](https://github.com/dfm/emcee) `EnsembleSampler` that allows us to store some inference-specific parameters before sampling and of course the samples themselves after sampling.\n",
    "\n",
    "Let's start with the first part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plus one dimension for the late T-stage's time parameter\n",
    "ndim = len(original_model.spread_probs) + 1\n",
    "\n",
    "# define the log-likelihood\n",
    "def log_prob_fn(theta, sys, early_p=0.3, max_t=10):\n",
    "    spread_probs, late_p = theta[:-1], theta[-1]\n",
    "    \n",
    "    if late_p > 1. or late_p < 0.:\n",
    "        return -np.inf\n",
    "    \n",
    "    t = np.arange(max_t + 1)\n",
    "    time_dists={\n",
    "        \"early\": lymph.utils.fast_binomial_pmf(t, max_t, early_p),\n",
    "        \"late\" : lymph.utils.fast_binomial_pmf(t, max_t, late_p)\n",
    "    }\n",
    "    \n",
    "    return sys.marginal_log_likelihood(\n",
    "        spread_probs, t_stages=[\"early\", \"late\"], time_dists=time_dists\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Warning \n",
    "\n",
    "    The provided log-likelihood function won't be stored anywhere! It is not possible to store arbitrary python code in an HDF5 file and retrieve it automatically in a safe manner.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Do the sampling & store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:11<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance fraction = 21.52 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this chain might be a little too short, but for the demo it's OK\n",
    "nstep, burnin = 200, 100\n",
    "\n",
    "with Pool() as pool:\n",
    "    original_sampler = lymph.utils.EnsembleSampler(\n",
    "        ndim, log_prob_fn, args=[original_model], pool=pool\n",
    "    )\n",
    "    original_sampler.run_mcmc(nstep)\n",
    "    \n",
    "print(f\"Acceptance fraction = {100 * np.mean(original_sampler.acceptance_fraction):.2f} %\")\n",
    "\n",
    "original_sampler.to_hdf5(\n",
    "    filename=demo_hdf5_file, \n",
    "    groupname=\"original\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make sure the chain of samples is actually stored by trying to retrieve it from the HDF5 file directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 120, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = lymph.utils.EnsembleSampler.get_chain_from_hdf5(\n",
    "    filename=demo_hdf5_file,\n",
    "    groupname=\"original\"\n",
    ")\n",
    "chain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first round has finished now. Let's see if we can repoduce all of that as intended.\n",
    "\n",
    "## Do it all again\n",
    "\n",
    "When we load a model instance from the HDF5 storage, all the settings, i.e. the graph, the diagnostic modalities and the loaded data, should still be the same as in the beginning. So let's check that with some `assert`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_model = lymph.utils.system_from_hdf5(\n",
    "    filename=demo_hdf5_file,\n",
    "    groupname=\"original\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('tumor', 'primary'): ['I', 'II', 'III', 'IV'],\n",
       " ('lnl', 'I'): ['II'],\n",
       " ('lnl', 'II'): ['III'],\n",
       " ('lnl', 'III'): ['IV'],\n",
       " ('lnl', 'IV'): []}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert recovered_model.graph == graph, \"Wrong graph!\"\n",
    "recovered_model.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MRI': [0.63, 0.81], 'PET': [0.86, 0.79]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert recovered_model.modalities == diagnostic_spsn, \"Wrong diagnostic modalities!\"\n",
    "recovered_model.modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">MRI</th>\n",
       "      <th colspan=\"8\" halign=\"left\">PET</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">contra</th>\n",
       "      <th colspan=\"4\" halign=\"left\">ipsi</th>\n",
       "      <th colspan=\"4\" halign=\"left\">contra</th>\n",
       "      <th colspan=\"4\" halign=\"left\">ipsi</th>\n",
       "      <th>tumor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>IV</th>\n",
       "      <th>I</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>IV</th>\n",
       "      <th>I</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>IV</th>\n",
       "      <th>I</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>IV</th>\n",
       "      <th>t_stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MRI                                                     PET         \\\n",
       "    contra                        ipsi                      contra          \n",
       "         I     II    III     IV      I     II    III     IV      I     II   \n",
       "0    False   True  False   True  False  False  False  False  False  False   \n",
       "1     True   True  False  False   True  False  False  False  False   True   \n",
       "2    False  False  False  False   True   True   True  False  False  False   \n",
       "3    False   True   True   True  False  False  False  False  False  False   \n",
       "4     True  False   True  False  False   True   True   True  False   True   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "195  False  False   True  False  False   True   True   True   True   True   \n",
       "196  False  False   True   True   True  False  False  False  False  False   \n",
       "197  False  False   True  False   True   True   True   True  False  False   \n",
       "198   True   True  False  False  False   True  False   True  False  False   \n",
       "199   True  False   True  False  False   True  False  False  False  False   \n",
       "\n",
       "                                                 info  \n",
       "                    ipsi                        tumor  \n",
       "       III     IV      I     II    III     IV t_stage  \n",
       "0    False  False  False  False  False  False   early  \n",
       "1    False  False  False  False  False  False   early  \n",
       "2    False  False   True   True  False   True    late  \n",
       "3     True   True  False  False  False  False   early  \n",
       "4    False  False  False  False   True   True   early  \n",
       "..     ...    ...    ...    ...    ...    ...     ...  \n",
       "195  False   True  False   True  False   True    late  \n",
       "196  False  False  False   True  False  False   early  \n",
       "197  False  False   True  False  False   True    late  \n",
       "198  False  False  False   True   True  False   early  \n",
       "199  False  False  False  False  False  False   early  \n",
       "\n",
       "[200 rows x 17 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert np.all(recovered_model.patient_data == synthetic_data), \"Wrong data!\"\n",
    "recovered_model.patient_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recovery worked! Since we want to do another sampling round which itself should be reproducable as well, we can immediately store the recovered model in a new group of the HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_model.to_hdf5(\n",
    "    filename=demo_hdf5_file,\n",
    "    groupname=\"recovered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the `EnsembleSampler`. Don't forget that the `log_prob_fn` needs to be specified, as it cannot be retrieved from an HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_sampler = lymph.utils.EnsembleSampler.from_hdf5(\n",
    "    log_prob_fn=log_prob_fn,\n",
    "    args=[recovered_model],\n",
    "    filename=demo_hdf5_file,\n",
    "    groupname=\"original\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recovered_sampler.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recovered_sampler.nwalkers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recovered sampler immediately has the correct number of dimensions and walkers and since we have passed the log-likelihood function to it already, we are ready for sampling again.\n",
    "\n",
    "Note that this recovery process does not reassign the previously stored chain of samples to the recovered sampler, since that'd be confusing as we want to sample new ones now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [08:33<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance fraction = 20.49 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this chain might be a little too short, but for the demo it's OK\n",
    "nstep, burnin = 200, 100\n",
    "\n",
    "with Pool() as pool:\n",
    "    # pool is only for multiprocessing. Can also be passed as kwargs to the \n",
    "    # `from_hdf5` function\n",
    "    recovered_sampler.pool = pool\n",
    "    recovered_sampler.run_mcmc(nstep)\n",
    "    \n",
    "print(f\"Acceptance fraction = {100 * np.mean(recovered_sampler.acceptance_fraction):.2f} %\")\n",
    "\n",
    "recovered_sampler.to_hdf5(\n",
    "    filename=demo_hdf5_file, \n",
    "    groupname=\"recovered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond that one can of course use the [`h5py`](https://docs.h5py.org/en/stable/) package or `pandas`' implemented capabilities to interact with the HDF5 file format to store and retrieve even more information, like a description of what was done or what exactly the log-likelihood does."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b6eded5f386e55fd051b894079e4370359bf13f51a44183870a4399bfd4d593"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
